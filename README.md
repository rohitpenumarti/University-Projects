# Undergraduate Projects

1. [PHYS 188](#PHYS-188-link)
2. [PHYS 240](#PHYS-240-link)
    1. [Chi-square Fitting of Noisy Data and Likelihood Modeling of Supernova Neutrino Data](#homework-1-link)
    2. [Non-linear Least Squares Fitting of Temperature Data](#homework-2-link)
    3. [Outlier Treatment and Bootstrapping, MCMC, and PCA](#homework-3-link)
    4. [Gaussian Process Regression, Mixture Modeling and Bootstrapping, and Model Selection](#homework-4-link)
3. [PSTAT 176](#PSTAT-176-link)
    1. [Binomial Option Pricing of Exotic Options Using Basic Monte Carlo Methods](#homework-1-link)
    2. [Binomial and Black Scholes Option Pricing using Basic Monte Carlo Methods](#homework-2-link)
    3. [Control Variates Analysis and Markowitz Mean-Variance Portfolio Optimization](#homework-3-link)
    4. [CAPM and Exponential Utility Maximization](#homework-4-link)
    5. [American Option Pricing](#final-project-american-option-pricing-link)
4. [Fourth Example](#fourth-examplehttpwwwfourthexamplecom)

## PHYS 188 ([link](https://github.com/rohitpenumarti/University-Projects/blob/dev/PHYS-188/Homework/Project3/Project3_288.ipynb))
The PHYS 188 folder contains a project focused on Neural Network Classification. It is part of a course in UC Berkeley's physics curriculum which I used to learn more in my free time. Link to the project file is above. The first part of the project focused on classification of MNIST data, using 40000 training images and 10000 images for testing, using the Keras package in python. I used several methods to attain the highest possible results. First, I used a deep neural net using Dense layers and grid searches to optimze hyperparameters to achieve the highest accuracy. Using this method, I created a basic architecture that achieved ~97.4% accuracy after 5 epochs. No advanced methods were used here. For the second method, I introduced convolutional neural networks which have been shown to be king in the field of image recognition. I created a more complex architecture which made use of convolution layers, pooling layers, a decaying learning rate, and dense layers. Using this algorithm, I was able to achieve ~99.4% accuracy in just 15 epochs. For higher accuracy, data augmentation and batch normalization can be used but in the process sacrificing computational time which can be mitigated to some extent with the use of a GPU. The second part of the project focused on classification of phases of particles in the 2D Ising model using tensorflow. I used simple dense layers and grid searches to optimize hyperparameters.

## PHYS 240 ([link](https://github.com/rohitpenumarti/University-Projects/tree/dev/PHYS%20240))
The PHYS 240 folder contains projects from my Statistics, Data Analysis, and Machine Learning for Physicists course.

### Chi-square Fitting of Noisy Data and Likelihood Modeling of Supernova Neutrino Data ([link](https://github.com/rohitpenumarti/University-Projects/blob/dev/PHYS%20240/Homework%20%231.ipynb))
For the first homework assignment, we were tasked with completing two problems. The goal of this problem set was to become familiarized with chi-squared fitting of data and creating and visualizing likelihood models of data. 

The first problem was concerned with chi-square fitting of noisy data. The first part asked us to simulate and graph random uniformly sampled points between -1 and 1 with gaussian noise added to is. Then, we were asked to fit the data using a chi-square fitting test, ignoring errors in x data. For this part The next part, we were asked to 

### Non-linear Least Squares Fitting of Temperature Data ([link](https://github.com/rohitpenumarti/University-Projects/blob/dev/PHYS%20240/Homework%20%232.ipynb))

### Outlier Treatment and Bootstrapping, MCMC, and PCA ([link](https://github.com/rohitpenumarti/University-Projects/blob/dev/PHYS%20240/Homework%20%233.ipynb))

### Gaussian Process Regression, Mixture Modeling and Bootstrapping, and Model Selection ([link](https://github.com/rohitpenumarti/University-Projects/blob/dev/PHYS%20240/HW4%20(Final%20Project).ipynb))

## PSTAT 176 ([link](https://github.com/rohitpenumarti/University-Projects/tree/dev/PSTAT%20176))
The PSTAT 176 folder contains projects from my Advanced Mathematical Finance Course. It focused on topics in option pricing, monte carlo simulation, and other miscellaneous material such as the Markowitz Mean-Variance portfolio optimization and material on interest rate swaps. The homeworks folder contains all homework coding projects which make use of different monte carlo simulation and variance reduction techniques such as anithetic variates, quasi-monte carlo, stratified sampling, importance sampling, and control variates. The final project is on pricing American options using the Longstaff-Schwartz algorithm and control variates to reduce variance in the estimate.

### Binomial Option Pricing of Exotic Options Using Basic Monte Carlo Methods ([link](https://github.com/rohitpenumarti/University-Projects/blob/dev/PSTAT%20176/Homeworks/Homework%201/Penumarti.Rohit.HW1.ipynb))

### Binomial and Black Scholes Option Pricing using Basic Monte Carlo Methods ([link](https://github.com/rohitpenumarti/University-Projects/blob/dev/PSTAT%20176/Homeworks/Homework%202/Penumarti.Rohit.HW2.ipynb))

### Control Variates Analysis and Markowitz Mean-Variance Portfolio Optimization ([link](https://github.com/rohitpenumarti/University-Projects/blob/dev/PSTAT%20176/Homeworks/Homework%203/Penumarti.Rohit.HW3.ipynb))

### CAPM and Exponential Utility Maximization ([link](https://github.com/rohitpenumarti/University-Projects/blob/dev/PSTAT%20176/Homeworks/Homework%204/Penumarti.Rohit.HW4.ipynb))

### American Option Pricing ([link](https://github.com/rohitpenumarti/University-Projects/blob/dev/PSTAT%20176/Final%20Project%20Report.ipynb))
